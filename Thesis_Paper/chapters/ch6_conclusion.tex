In this thesis, we evaluated different synthetic datasets generated using parametric, non-parametric, and generator network-based data synthsis algorithms in the study to produce synthetic data for the Covid-19 Trend and Impact (CTIS) dataset. We reviewed the state of technology proposed for synthetic data generation and selected a few algorithms for extensive application. Subsequently, we proposed a experiment framework with 4 steps (step 1: data preprocessing; Step 2: data synthesis for categorical variables; Step 3: data synthesis for numerical variables; Step 4: utility evaluation and risk assessment;) and especially to deal with categorical and numerical variables and examine the difference between the performance of data synthesizers applied on them, the data synthesis phrase was broken down into two stages, respectively. Finally, we experimented with selected data synthesizers applied on the original data scource to determine the quality of various synthetic datasets in terms of overall data utility, univariate data utility, analysis-specific utility (by fitting linear regression model with selected predictors), and replication analysis.

We conclude our work by re-examining the research objective and assess which synthetic data generation actually has the potential to be used in a real-world environment by comparing their corresponding data utility and risk assessment. We evaluate the strenghts and limitations of different algorithms based data synthesizers and discuss its relevance and utility. Finally we provide insights into future research opportunities.

\subsection{Review of Research Objective}
\label{subsec:review}
Our experiments revealed that non-parametric data synthesizers outperformed parametric data synthesizers in terms of general propensity score measure and analysis-specific utility evaluation. Specifically, decision tree and polytomous regression-based methods demonstrated the best performance, particularly with respect to the standardized propensity score measure. Moreover, the decision tree-based data synthesizer ranked the highest in terms of analysis-specific utility evaluation, as evidenced by fitting linear regression models with synthetic values compared to the original dataset. Nevertheless, our study also highlighted the potential limitation of higher model complexity in constructing non-parametric data synthesizers, which may result in the failure to restore the corresponding data utility.

Regarding univariate data utility, we observed that the synthesizing of categorical variables generally performed well when no newly generated records were involved. However, synthesizing numerical variables could be more challenging, resulting in a loss of data utility compared to synthesizing binary variables with fewer levels. This is mainly due to the difficulty in preserving complex relationships and patterns between different variables in the original dataset. Additionally, data synthesizers demonstrated poor performance in synthesizing categorical variables with a substantial number of levels.

In addition to evaluating data utility, we also performed a risk disclosure analysis using a replicated uniques score. Our study demonstrated that parametric data synthesizers based on linear regression outperformed other methods due to the generation of new records that do not exist in the original dataset.

Notably, the GEM-based data synthesizer, a generator network-based algorithm, generally demonstrated the worst performance in terms of data utility evaluation. This finding may be due to the inability of neural network-based data synthesizing algorithms to capture the interactions between query data. Unlike image or audio data, which have spatial interactions between cells, query data is typically stored as tabular data, making it challenging for these methods to detect relationships between variables.

\subsection{Limitation and Future work}
\label{subsec:future}
One potential limitation of our study is the lack of tuning of inbuilt parameters in each data synthesizer during the categorical data synthesis process. For instance, we did not vary the number of trees grown by the random forest and bagging-based data synthesizers, which were kept constant at 10. By exploring different parameter settings, it may be possible to generate synthetic data with even higher utility, which is an avenue for future research.

Looking ahead, we could investigate the use of other data synthesizers and compare their performance with the methods employed in this study. For instance, we could explore the application of generative adversarial networks (GANs) variational autoencoders (VAEs), and differential privacy (DP) for synthetic data generation. Moreover, we could examine the performance of data synthesizers on diverse datasets with varying sizes and structures, which may help identify the most effective methods for different data types. Finally, we could explore the potential benefits of combining multiple data synthesizers to generate high-quality synthetic datasets. These research directions hold the promise of advancing the field of synthetic data generation and enhancing the use of synthetic data in diverse domains.