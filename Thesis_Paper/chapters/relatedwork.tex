In this chapter, general definition of data privacy and the necessity to maintain data privacy are described. 
Furthermore, in order to keep data privacy, this chapter also presents an overview of methods to achieve the 
goal of privacy preserving data analysis and publication, which have been adopted in several domains. 
Here, we want to emphasize the use of synthetic data and one of its most popular applications, 
i.e., differentially private synthetic data, that are able to prevent disclosure in the process of synthetic data generation.

\subsection{Data Privacy}
\label{subsec:dataprivacy}
It is well-acknowledged that we have entered a data-driven world and data are 
often regarded as significant constituents for our society. At the same time, 
an open society can also learn from these data so as to develop feasible 
and practical policy guidelines \citep{evans2021statistically}. Especially 
during the outbreak of coronavirus disease 2019 (COVID-19), more and more increased concerns are raised that it is 
essential for a society to utilize such data, which are widely-spread in the population
and analyzed with regard to various perspectives, to advance sophiscated planning
and develop more concrete social welfare benefits for the citizens. Consequently,
both seen from the public health perspective and the economy perspective, the on-going
COVID-19 global pandemic serves as a rigid reminder that detailed data are urgently 
needed to assist in decision making, damage control scenarios. Regardless of prevalent
consensus reached to leverage more microdata, the inappropriate use of such 
information can cause harm in data confidentiality and privacy as sometimes the attacks
from an intruder may result in the leakage of an individual's sensitive information, e.g., identity, 
address and salary, etc.


On the premise of possible outcomes brought by the misuse of microdata, it is crucial that 
we encourage proper and legal use of the collected datasets. Holding this motivation, researchers 
have developed a variety of strategies aiming to avoid the disclosure of sensitive records while
revealing these specific information to the public \citep{duncan2011statistical}. In the early times, 
several traditional methods have been proposed to limit data disclosure with strategies like top-coding,
swapping or data suppression. Nevertheless, with increased computing power and more data access demanded by
the public, the risks of data disclosure are often seen as underestimated using simply these traditional
protection strategies, where instances of privacy breaches can be found simultaneously in the public and 
private sectors \citep{de2015unique}.

Alternatively, with the purpose to reach the trade-off between data disclosure protection and broad
data access, the idea of synthetic data has been released. When using this approach, we make a model
fitted to the microdata and the corresponding outputs from the fitted model are then used to replace
the original values in the previous information.


\subsection{An Overview of Data Synthesis Approaches}
\label{subsec:datasynthesis}
The field of employing synthetic data to avoid data statistical disclosure has been introduced by \citet{rubin1993statistical}
and \citet{little1993statistical} in the context of learning multiple imputation (MI) for nonresponse \citep{little2019statistical}.
In their work, they showed the possibility to get these sentitive values replaced with "imputed" values
rather than impute data for those missing records in the original dataset. With the application of this multiple
imputation framework, ramdom draws sampled from these imputed populations can then be circulated to the public. In more
extreme cases, when it is necessary to avoid the release of original data completely, those instances from
the original sample can also be displaced by samples from the imputation model.

Depending on the level of protection prone to specific scenarios, data synthesis methods are categorized to two groups, i.e.,
partial synthesis and full synthesis. For partially synthetic data, only some parts of the original records are synthesized. 
On the contrary, the entire dataset are replaced by synthetic values with the utilizatio of full synthesis methods specifically.
It is evident to infer that the desired protection level is high when applying fully synthetic data methods, as original instances
are completely excluded. 



\subsubsection{Computer Science Approaches}
\label{subsubsec:csapproach}
Despite the origin and early development of synthetic data, in computer science, the data Synthesis
approach did not raise much interest in the study of data privacy until the advent of various privacy
standards. In order to cater to people's requirement of privacy protection, scientists have defined
several popular data privacy standards such as $k-$anonymity \citep{sweeney2002k}, $l-$diversity \citep{machanavajjhala2007diversity}
and $t-$closeness \citep{li2006t}. In the following context, we try to shortly introduce the key ideas of the three popular
standards.

\paragraph{$k-$anonymity}

\paragraph{$l-$diversity}

\paragraph{$t-$closeness}




\subsubsection{Statistical Approaches}
\label{subsubsec:statsapproach}

\subsubsection{Differentially Private Data Synthesis}
\label{subsubsec:dpds}



